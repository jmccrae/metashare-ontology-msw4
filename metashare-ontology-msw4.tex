\documentclass{llncs}
\usepackage{color}
\usepackage{array}

\begin{document}

\title{Metashare as an ontology for the interoperability of linguistic datasets}

%
\titlerunning{Metashare ontology}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%

% This is not the final order!
\author{Philipp Cimiano\inst{1} \and Jorge Gracia\inst{2} \and Penny Labropoulou\inst{3} \and John P. McCrae\inst{1} \and V\'ictor Rodr\'iguez Doncel\inst{2} \and Marta Villegas\inst{4}}
%
\authorrunning{Cimiano et al.} % abbreviated author list (for running head)
%
%
\institute{Cognitive Interaction Technology, Excellence Cluster, Bielefeld
    University, Inspiration 1, D-33619 Bielefeld, Germany, \\
    \email{\{cimiano, jmccrae\}@cit-ec.uni-bielefeld.de}
\and
    Ontology Engineering Group, Universidad Polit\'ecnica de Madrid, Boadilla del Monte, Madrid, Spain \\
    \email{\{jgracia, vrodriguez\}@fi.upm.es}
\and
    ILSP/Athena R.C., Athens, Greece, \\
    \email{penny@ilsp.athena-innovation.gr}
\and
    University Pompeu Fabra, Barcelona, Spain, \\
\email{marta.villegas@upf.edu}}
    
\maketitle              % typeset the title of the contribution

\begin{abstract}
    \keywords{keywords}
\end{abstract}

\section{Introduction}
\label{sec:introduction}

META-SHARE~\cite{piperidis2012meta} is a subproject of META-NET aiming to create high-quality metadata
for a large number of language resources and make them available in a structured
form. Up until now the main methodology that META-SHARE has used to make data
available is by means of XML Schema Definitions (XSD) and XML description of
individual language resources conforming to these definitions. However,
META-SHARE still covers only a small percentage of language resources and its
resource-intensive curation methodology means it is unlikely to cover all
language resources. In contrast, there have been a number of schemes that have
attempted to collect much more metadata from either existing institutional
repositories~\cite[CLARIN]{broeder2010data} or by crowd-sourcing this data from
researchers~\cite[LRE-Map]{calzolari2012lre}. The former method has lead to
data in different incompatible formats and the latter to noisy, incomplete and
duplicative records.

In this paper, we propose a solution to these issues by means of the development
of a single ontology for the representation of language resources based on the
original META-SHARE schema, but represented using the Web Ontology
Language~\cite{motik2012owl} and building on an existing standard, namely
DCAT~\cite{maali2014data}. This is a necessary step to the development of a
resource called LingHub\footnote{\url{http://linghub.org/}}, which incorporates
META-SHARE data as well as data from other sources and aims to make it queriable
by humans and software agents.

We hope that this will improve the representation
of language resource metadata in two fronts. Firstly, \textit{RDF is super, we
    can SPARQL it, yada, yada... reasoning... yada, yada, Web technologies are
the future}. Secondly, we hope that the use of this ontology will enable the
representation of metadata in a manner that allows existing resources to adopt a
common core vocabulary, while still being able to represent specific extensions
to their existing model and we evaluate this hypothesis by reference to the
CLARIN and LRE-Map data models.

As an ancillary contribution of this paper, we also describe our experience in
technically converting the META-SHARE schema and data to RDF. This was unusually
complex as the META-SHARE schema is very complex and as such we needed to
develop a new tool, we call the Lightweight Invertible XML to RDF Mapping
Language (LIXR), and we demonstrate quantitatively how this ameliorated the
process of conversion, and thus as a result proved to be a tool that may
significantly help in future conversions from XML.

The rest of this paper is structured as follows: In section
\ref{sec:relatedwork} we will describe the related work in the fields of
language resource metadata and metadata harmonization. The development of the
META-SHARE ontology is described in section \ref{sec:ontology} and then in
section \ref{sec:linghub} we describe how the data was converted for use in the
LingHub portal and how the ontology was used for other data sources in that
resource. Finally, in section \ref{sec:discussion} we consider the broader
impact of this ontology as a tool for computational linguists and as a method to
realize an architecture of (linked) data-aware services.

\section{Related Work [JPM]}
\label{sec:relatedwork}

The task of finding common vocabularies for linguistics is of wide interest and
several general ontologies for linguistics have been proposed. The General
Ontology for Linguistic Description~\cite[GOLD]{farrar2002common} was proposed
as a common model for linguistic data, but its relatively limited scope and low
coherence has not lead to wide-spread adoption. An alternative approach that has
been proposed is to use ontologies to create coherence among the resources, in
particular either by using ontologies to align different linguistic
schemas~\cite{chiarcos2012ontologies} or by means of agreed
identifiers~\cite{kemps2008isocat}. For the particular case of linguistic
metadata there have been a number of attempts to define basic metadata for
linguistic resources, most notable the Open Language Archive
Community~\cite[OLAC]{bird2001olac} which built on the Dublin Core metadata. A
similar initiative, that provided more structured metadata was the ISLE Metadata
Initiative~\cite[IMDI]{broeder2001imdi}, that provided an import influence on
the META-SHARE model.

The CLARIN project has played an important role in collecting information about
metadata and in particular proposed a common system by which metadata from
disparate sources could be aggregated. This system, called the Component
Metadata Infrastructure~\cite{broeder2012cmdi}, involved the creation of
individual data profiles for each resource, by means of a customized XSD scheme.
As we observe in section \ref{sec:harmonization}, this has in practice merely
resulted in each contributing institute using its own scheme, with very little
commonality between different institutes. To improve this situation it was
recently proposed that the conversion of these CMDI schemas to RDF would enable
better interoperability~\cite{durco2014clarin}, however it is not clear if this
project has been realized.\footnote{JPM: I emailed Menzo Windhouwer about this
and may change this statement based on his response, if any}

\section{The META-SHARE Ontology}
\label{sec:ontology}

\subsection{Original MS XSD schema [PL]}
\label{sec:xsd}

\subsection{Purpose of the ontology [MV,JG,JPM]}
\label{sec:purpose}
(e.g., why do RDF and OWL for an already defined vocabulary?) 
\subsection{Formal modelling and mapping issues [MV, JPM, PL]}

When mapping an XML scheme to RDF there are naturally differences that must be
accounted for, which generic mapping methodologies cannot accommodate without
tending to a high degree of verbosity. The META-SHARE metadata model is formalised in a XSD schema that 'transcodes' a component-based model as suggested by CLARIN~\cite{broeder2012cmdi}. Essentially, the component-based approach revolves around two central concepts: \emph{elements} and \emph{components}. \emph{Elements} are used to encode specific descriptive features of the resources and are linked to conceptually similar existing elements in the Dublin Core and/or the ISOcat registry. \emph{Components} are complex elements and can be seen as bundle of semantically coherent \emph{elements}.

In the META-SHARE XSD schema, \emph{elements} are formalized as simple elements whereas \emph{components} are formalized as complex-type elements. When mapping the XSD schema to RDF, \emph{elements} can be naturally understood as properties (e.g. name, gender, etc.). \emph{Components} (i.e. complex-type elements), however,  deserve a careful analysis. General mapping rules from XSD to RDF stablish that a local element with complex type translates into an object property and a Class. An insight analysis of the META-SHARE schema showed that the straightforward application of such a principle may derive into unnecessary verbose graphs. 

META-SHARE distinguishes between three kinds of \emph{components}, namely: 'special status components', 'linked components' and 'bare components'. The former include concepts such as person and document and they can be attached to various \emph{components} performing different roles (i.e. creator, validator, documentation, etc.). 'Linked components' can be understood as relations between \emph{components} and include concepts such as validationReport or validator, among many others. Finally, 'bare components' are used to group together semantically coherent information (i.e. metadataInfo, validationInfo etc.). In the XSD schema, 'special status components' are formalised as complex types whereas 'linked components' are complex elements. Thus, when applying the conversion rules, the ‘special status components’ become Classes and the ‘linked components’ become object properties which correctly captures the semantics behind. For 'bare components' things are more complex as they are formalised as both complex elements and complex types. This means that the general conversion rule will produce an object property and the corresponding Class which, in most cases, may be unnecessary. For example: in the META-SHARE schema, the resourceInfo node contains a number of elements which organise information into coherent sets~\footnote{We use XPath expressions. Number in brackets shows node’s cardinality.}: 

{\footnotesize
\begin{verbatim}
resourceInfo/identificationInfo(1)/...
resourceInfo/distributionInfo(1)/... 
resourceInfo/contactPerson(n)/...
resourceInfo/metadataInfo(1)/... 
resourceInfo/versionInfo(1)/... 
resourceInfo/validationInfo(n)/...
resourceInfo/usageInfo(1)/...
resourceInfo/resourceDocumentationInfo(1)/...
resourceInfo/resourceCreationInfo(1)/...
resourceInfo/relationInfo(1)/...
resourceInfo/resourceComponentType(1)/...
\end{verbatim}}


For elements such as the identificationInfo above, the application of the rule will produce an unnecessary node. Following~\cite{Villegas2014}, we identified potentially removable nodes before the actual RDFication process. The criteria applied take into account the tree structure of the nodes, their cardinality and the XPath axes. Thus, embedded complex elements with cardinalityMax=1 are identified as potentially removable, provided they do not contain text nor attributes. This allows for a simplification of the model, as exemplified below.

{\footnotesize
\begin{verbatim}
resource/identificationInfo/resourceName
resource/identificationInfo/description
resource/identificationInfo/resourceShortName
resource/identificationInfo/url
…
becomes

resource/resourceName
resource/description
resource/resourceShortName
resource/url
…
\end{verbatim}}


Note that such a simplification rule can be applied provided this does not derive in sibling conflicts: promoted nodes may cause naming conflicts in their new axe. Thus, a careful checking is needed in order to avoid possible clashes.

Besides the 'bare elements' described so far, a number of potentially superfluous nodes were also identified: namely complex elements with one and only one simple element. This is, for example, what happens with the path validationInfo/validationTool/targetResourceNameURI. In such cases the terminal node can be removed.



Beyond this, we made the following extensions to our mapping strategy:

\begin{itemize}
    \item We shorten some names such as ConformanceToBestStandardsAndPractices
        \textcolor{red}{JPM: Perhaps we introduce sameAs links to handle this}
    \item Developed novel classes based on existing values, e.g.,
        $\mathrm{Corpus} \equiv \exists \mathrm{resourceType}.\mathrm{corpus}$
    \item Removing unnecessary properties such as {\tt versionInfo}.
    \item Generalized elements such as {\tt userNature}, {\tt
        notAvailableThroughMetashare}
    \item Grouping similar elements under novel superclasses, e.g., {\tt
        DiscourseAnnotation}, {\tt genre}
    \item Extending existing classes with new values and including new
        properties (see section \ref{sec:licensing}
\end{itemize}

\subsection{Interface with DCAT and other vocabularies [JPM]}
\label{sec:dcat}

The META-SHARE model can be considered broadly similar to DCAT in that there are
classes that are nearly an exact match to ones in DCAT for three out of four
cases. DCAT's \emph{dataset} corresponds nearly exactly to the \emph{resource
info} tag and similarly, \emph{distributions} are similar to \emph{distribution
info} classes and \emph{catalog record} is similar to \emph{metadata info}. The
fourth main class, \emph{catalog} covers a level not modelled by META-SHARE. 

DCAT uses Dublin Core properties for many parts of the metadata, and often these
properties are in fact deeply nested into the description. For example, language
is found in several places deeply nested under six
tags~\footnote{{\tt resourceInfo} $>$ {\tt resourceComponentType} $>$ {\tt
    corpus}* $>$ {\tt corpusMediaType} $>$ {\tt corpusVideoInfo} $>$ {\tt
languageInfo} (* multiple tags also lead to the language information)}.
Similarly, it also the case that some Dublin Core properties are not directly
specified in the META-SHARE model, but can be inferred from related properties,
e.g., Dublin Core's `contributor' follows from people indicated as `annotators',
`evaluators', `recorders' or `validators'. Similarly, several DCAT specific-properties, such as `download URL', are nearly
exactly equivalent to those in Metashare but occur in places that do not fit the
domain and range of the properties. In this particular case, it was a simple fix
to move the property to the enclosing {\tt DistributionInfo} class.
Inevitably, several properties from DCAT did not have equivalences in
META-SHARE, notably `keyword' and `byte size'. We \textcolor{red}{did something
about this... I am not sure what though}

\subsection{Licensing module [VRD, PL]}
\label{sec:licensing}
\textcolor{red}{Skeleton}

We describe first the Metashare schema, whose licensing information is described in an independent XML Schema file, available on git \footnote{\url{https://github.com/metashare/META-SHARE/blob/master/misc/schema/v3.0/META-SHARE-LicenseMetadata.xsd}}. 

%SECOND: We then describe Marta's effort, and the META-SHARE ontology which is also publicly available\footnote{\url{https://raw.githubusercontent.com/martavillegas/metadata/master/MetaShare.ttl}}.

We discuss on the needs that motivated the evolution from the previous model. We describe (if not done before) also the precedure and methodology.

Short introduction on the ODRL vocabulary. 

We describe the most important changes that we have introduced.

And going beyond ODRL: License Templates as an easy entry points for Semantic Web - laymans.

Example of license template, example of license. Directly in TTL. Maybe introducing a figure depecting what is metadata for resource/distrubiont/license? 

\section{META-SHARE in LingHub}
\label{sec:linghub}

LingHub~\footnote{\url{http://linghub.org}} is a large resource containing information about a wide range of
language resources, but unlike META-SHARE it does not directly collect this
information, but instead harmonizes the metadata from a wide range of sources.
In this section, we will first describe how the original META-SHARE data was
translated into RDF and the alignment with DCAT~\cite{maali2014data}, previously
described, was achieved. Furthermore, we will then consider how we have used the
META-SHARE vocabulary as a base vocabulary to align terms from other resources
included in LingHub.

\subsection{Mapping META-SHARE to RDF [JPM]}
\label{sec:conversion}

When translating XML documents into RDF, one of the most common approaches is
based on Extensible Stylesheet Language Transformations
(XSLT)~\cite{wustner2002converting,van2008xml,borin2014representing}, which has
been extended by some authors into a significant
framework~\cite{lange2009krextor}. However, XSLT has a number of disadvantages
for this task:

\begin{itemize}
    \item The set of functions and operators suported by most processors is
        limited.
    \item Limited ability to declare new functions.
    \item Does not allow stream (SAX) processing of large files.
    \item XSLT is a one-way transformation language and it is not this possible
        to `round-trip' the conversion, i.e., convert RDF to XML.
    \item XSLT syntax is expressed in XML and thus is very verbose and
        aesthetically unpleasing. For this reason, many people use alternative
        more compact syntaxes\footnote{Compact XML:
        \url{https://pythonhosted.org/compactxml/}}\footnote{Jade:
        \url{http://jade-lang.com/}}
\end{itemize}

Furthermore, the META-SHARE syntax is very complex consisting of 111 complex
types and 207 simple types. As such we deemed that the development of a new
language for transformation and writing our converter in that language would
take less development effort than writing a conversion entirely in XSLT. The
mapping methodology we developed is a domain-specific
langauge~\cite{fowler2010domain} called Lightweight Invertible XML to RDF
Conversion (LIXR) and aims to improve on the situation by fixing the concerns
above. 

To begin with we selected the Scala programming language as the basis for LIXR
as it has a proven syntactic flexibility that makes it easy to write
domain-specific languages~\cite{wampler2008programming}. A simple example of a
LIXR mapping is given below:

{\footnotesize
\begin{verbatim}
object Metashare extends eu.liderproject.lixr.Model {
  val dc = Namespace("http://purl.org/dc/elements/1.1/")
  val ms = Namespace("http://purl.org/ms-lod/MetaShare.ttl#")
  val msxml = Namespace("http://www.ilsp.gr/META-XMLSchema")

  msxml.resourceInfo --> (
    a > ms.ResourceInfo,
    handle(msxml.identificationInfo)
  )

  msxml.identificationInfo --> (
    forall(msxml.resourceName)(
        dc.title > (content @@ att("lang"))
    )
  )
}
\end{verbatim}}

In this example, we first create our model extending the basic LIXR model and
define namespaces as dynamic Scala objects\footnote{This is a newer feature of
    Scala only supported since 2.10 (Jan 2013)}. We then make two mapping
declarations for the tags {\tt resourceInfo} and {\tt identificationInfo}. LIXR (as 
XSLT) simply searches for a matching declaration at the root of the XML document
to begin the transformation. Having matched the {\tt resourceInfo} tag, the system
first generates the triple that states that the base element has type
{\tt ms:resourceInfo}, and then `handles' any children {\tt identificationInfo} tags by
searching for an appropriate rule for each one. For {\tt identificationInfo} the
system generates a triple using the {\tt dc:title} property whose value is the
content of the {\tt resourceName} tag tagged with the language given by the
attribute {\tt lang}.

\begin{table}
    \begin{center}
    \begin{tabular}{p{4cm}|cccc}
        Name        & Tags      & Implementation & LoC    & LoC/Tag \\
        \hline
        TBX         & 48        & Java           & 2,752  & 57.33   \\
        CLARIN (OLAC-DMCI) & 79 & XSLT           & 404    & 5.11    \\
        CLARIN (OLAC-DMCI) & 79 & XSLT (Compact Syntax) & 255    & 3.22    \\
        \hline
        TBX         & 48        & LIXR           & 197    & 4.10    \\
        CLARIN (OLAC-DMCI) & 79 & LIXR           & 176    & 2.23    \\
        MetaShare   & 730       & LIXR           & 2,487  & 3.41    \\
    \end{tabular}
\end{center}
    \caption{\label{tab:locs}Comparison of XML to RDF mapping implementations,
    by number of tags in XML schema, and non-trivial lines of code (LoC)}
\end{table}

To evaluate the effectiveness of our approach we compared directly with two other
XML to RDF transformations, we had carried out in this project, and
reimplemented them using the LIXR language. In particular these were the TBX
model~\cite{iso30042} as well as the OLCA-DMCI profile of the CLARIN
metadata~\footnote{\url{http://catalog.clarin.eu/ds/ComponentRegistry/rest/registry/profiles/clarin.eu:cr1:p\_1288172614026/xsd}}. In table \ref{tab:locs}, we see the
effort to implement these using LIXR is approximately half of using XSLT and
about ten times less than writing a converter from scratch. 

In addition to the reduction in effort using this approach, we also note several
other advantages of the LIXR approach, due to its declarative declaration

\begin{itemize}
    \item We can easily switch to using a stream-based parse for XML (e.g., SAX)
        so we can process large files without having to use much memory
    \item A reverse mapping can be extracted that re-generates the XML from the
        outputted RDF
    \item We can extract the type, range and domain of RDF entities generated
        during this procedure. This export formed the initial version of the
        ontology described in this paper
\end{itemize}

\subsection{Harmonizing other resources with META-SHARE [JPM]}
\label{sec:harmonization}

LingHub brings resources from a wide-range of sources and while we can use
standards such as DCAT and Dublin Core to guarantee a common representation of the basic
Metadata of a resource, there does not a standard for the represenation of
metadata specific to linguistics. For that reason, we use the META-SHARE model
as a standard for other resources to use in LingHub. In particular, we will
focus on the application of META-SHARE as a model to harmonize CLARIN data. The
CLARIN repository describes its resources using a small common set of metadata
and a larger description defined by the Component Metadata
Infrastructure~\cite[CMDI]{broeder2012cmdi}. These metadata schemes are
extremely diverse as shown in table \ref{tab:clarin-types}.

\begin{table}
    \begin{center}
    \begin{tabular}{l|lc}
        Component Root Tag & Institutes & Frequency \\
        \hline
        Song               & 1 (MI)     & 155,403   \\
        Session            & 1 (MPI)    & 128,673   \\
        OLAC-DcmiTerms     & 39         &  95,370   \\
        mods               & 1 (Utrecht)&  64,632   \\
        DcmiTerms          & 2 (BeG,HI) &  46,160   \\
        SongScan           & 1 (MI)     &  28,448   \\
        media-session-profile  & 1 (Munich) &  22,405   \\
        SourceScan         & 1 (MI)     &  21,256   \\
        Source             & 1 (MI)     &  16,519   \\
        teiHeader          & 2 (BBAW, Copenhagen) &  15,998   \\
    \end{tabular}
    \end{center}
    \caption{\label{tab:clarin-types}The top 10 most frequent component types in
    CLARIN and the institutes that use them. Abbreviations: MI=Meertens Institute (KNAW), 
    MPI=Max Planck Insitute (Nijmegen), BeG=Netherlands Institute for Sound and Vision,
HI=Huygens Institute (KNAW), BBAW=Berlin-Brandenburg Academy of Sciences}
\end{table}

\section{Discussion}
\label{sec:discussion}

\subsection{Applications of the MetaShare model (beyond LingHub) [MV]}
\label{sec:applications}

\subsection{Challenges and future outlooks [PC]}
\label{sec:challenges}

\section{Conclusion [JG]}
\label{sec:conclusion}

\bibliographystyle{splncs03}
\bibliography{metashare-ontology-msw4}

\end{document}
